---
title: Memory
description: Enable conversation memory and personalization features in LibreChat
---

# Memory

## Overview

Memory in LibreChat allows the system to remember information across conversations, providing a more personalized and context-aware experience. When enabled, the AI can recall user preferences, important facts, and conversation context to enhance future interactions.

<Callout type="important" title="⚠️ Configuration Required">
- Memory functionality must be explicitly configured in your `librechat.yaml` file to work. It is not enabled by default.
- Currently, memory only works when using agents.
</Callout>

## Key Features

- **Persistent Context**: Information learned in one conversation can be recalled in future conversations
- **User Control**: When enabled, users can toggle memory on/off for their individual chats
- **Customizable Storage**: Control what types of information can be stored using valid keys
- **Token Management**: Set limits on memory usage to control costs
- **Agent Integration**: Use AI agents to intelligently manage what gets remembered

## Configuration

To enable memory features, you need to add the `memory` configuration to your `librechat.yaml` file:

```yaml filename="librechat.yaml"
version: 1.2.8
cache: true

memory:
  disabled: false  # Set to true to completely disable memory
  personalize: true  # Gives users the ability to toggle memory on/off, true by default
  tokenLimit: 2000  # Maximum tokens for memory storage
  messageWindowSize: 5  # Number of recent messages to consider
  agent:
    provider: "openAI"
    model: "gpt-4"
```

The provider field should match the accepted values as defined in the [Model Spec Guide](/docs/configuration/librechat_yaml/object_structure/model_specs#endpoint).

**Note:** If you are using a custom endpoint, the endpoint value must match the defined custom endpoint name exactly.

See the [Memory Configuration Guide](/docs/configuration/librechat_yaml/object_structure/memory) for detailed configuration options.

## How It Works

### 1. Information Storage
When memory is enabled, the system can store:
- User preferences (communication style, topics of interest)
- Important facts and context from conversations
- Personal information explicitly shared by users
- Ongoing projects or tasks mentioned

### 2. Context Window
The `messageWindowSize` parameter determines how many recent messages are analyzed for memory updates. This helps the system decide what information is worth remembering.

### 3. User Control
When `personalize` is set to `true`:
- Users see a memory toggle in their chat interface
- They can enable/disable memory for individual conversations
- Memory settings persist across sessions

### 4. Valid Keys
You can restrict what types of information are stored by specifying `validKeys`:

```yaml filename="memory / validKeys"
memory:
  validKeys:
    - "user_preferences"
    - "conversation_context"
    - "learned_facts"
    - "personal_information"
```

## Best Practices

### 1. Token Limits
Set appropriate token limits to balance functionality with cost:
- Higher limits allow more comprehensive memory
- Lower limits reduce processing costs
- Consider your usage patterns and budget

### 2. Custom Instructions
When using `validKeys`, provide custom instructions to the memory agent:

```yaml filename="memory / agent with instructions"
memory:
  agent:
    provider: "openAI"
    model: "gpt-4"
    instructions: |
      Store information only in the specified validKeys categories.
      Focus on explicitly stated preferences and important facts.
      Delete outdated or corrected information promptly.
```

### 3. Privacy Considerations
- Memory stores user information across conversations
- Ensure users understand what information is being stored
- Consider implementing data retention policies
- Provide clear documentation about memory usage

## Examples

### Basic Configuration
Enable memory with default settings:

```yaml filename="Basic memory config"
memory:
  tokenLimit: 2000
  agent:
    provider: "openAI"
    model: "gpt-4.1-mini"
```

### Advanced Configuration
Full configuration with all options:

```yaml filename="Advanced memory config"
memory:
  disabled: false
  validKeys: ["preferences", "context", "facts"]
  tokenLimit: 3000
  personalize: true
  messageWindowSize: 10
  agent:
    provider: "anthropic"
    model: "claude-3-opus-20240229"
    instructions: "Remember only explicitly stated preferences and key facts."
    model_parameters:
      temperature: 0.3
```

For valid model parameters per provider, see the [Model Spec Preset Fields](/docs/configuration/librechat_yaml/object_structure/model_specs#preset-fields).

### Using Predefined Agents
Reference an existing agent by ID:

```yaml filename="Memory with agent ID"
memory:
  agent:
    id: "memory-specialist-001"
```

## Troubleshooting

### Memory Not Working
1. Verify memory is configured in `librechat.yaml`
2. Check that `disabled` is set to `false`
3. Ensure the configured agent/model is available
4. Verify users have enabled memory in their chat interface

### High Token Usage
1. Reduce `tokenLimit` to control costs
2. Decrease `messageWindowSize` to analyze fewer messages
3. Use `validKeys` to restrict what gets stored
4. Review and optimize agent instructions

### Inconsistent Memory
1. Check if users are toggling memory on/off
2. Verify token limits aren't being exceeded
3. Ensure consistent agent configuration
4. Review stored memory for conflicts

## Related Features

- [Agents](/docs/features/agents) - Build custom AI assistants
- [Presets](/docs/user_guides/presets) - Save conversation settings
- [Fork Messages](/docs/features/fork) - Branch conversations while maintaining context 