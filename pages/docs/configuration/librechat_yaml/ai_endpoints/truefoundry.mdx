---
title: TrueFoundry AI
description: Example configuration for TrueFoundry AI Gateway
---

# [TrueFoundry Docs](https://docs.truefoundry.com/docs/introduction)

> TrueFoundry API key: [app.truefoundry.com](https://app.truefoundry.com/)

**Notes:**
- TrueFoundry is a cloud-native AI/ML platform that provides a comprehensive AI Gateway for managing, deploying, and scaling AI models on Kubernetes.
- TrueFoundry integrates with LibreChat through its AI Gateway, offering unified API access, intelligent routing, observability, rate limiting, and enterprise-grade security.
- The platform supports 250+ AI models and provides features like load balancing, fallback mechanisms, and cost optimization for production deployments.
- TrueFoundry can be deployed on your own cloud (AWS, GCP, Azure) or on-premises, ensuring data sovereignty and compliance with security requirements.
- The AI Gateway provides advanced observability with analytics, logs, and prompt management capabilities for comprehensive monitoring.

## Using TrueFoundry AI Gateway with OpenAI Models
```yaml filename="librechat.yaml"
      - name: "TrueFoundry"
        apiKey: "${TRUEFOUNDRY_API_KEY}"
        baseURL: "${TRUEFOUNDRY_GATEWAY_URL}"
        headers:
            x-tfy-api-key: "${TRUEFOUNDRY_API_KEY}"
            x-tfy-workspace-id: "${TRUEFOUNDRY_WORKSPACE_ID}"
        models:
            default: ["gpt-4o-mini", "gpt-4o"]
            fetch: true
        titleConvo: true
        titleModel: "current_model"
        summarize: false
        summaryModel: "current_model"
        forcePrompt: false
        modelDisplayLabel: "TrueFoundry:OpenAI"
        iconURL: https://www.truefoundry.com/favicon.ico
```

## Using TrueFoundry AI Gateway with Open Source Models
```yaml filename="librechat.yaml"
    - name: "TrueFoundry-OSS"
      apiKey: "${TRUEFOUNDRY_API_KEY}"
      baseURL: "${TRUEFOUNDRY_GATEWAY_URL}"
      headers:
        x-tfy-api-key: "${TRUEFOUNDRY_API_KEY}"
        x-tfy-workspace-id: "${TRUEFOUNDRY_WORKSPACE_ID}"
        x-tfy-model-config: "llama-3.2-config"
      models:
        default: ["llama-3.2-90b-instruct", "mistral-8x7b-instruct"]
        fetch: true
      titleConvo: true
      titleModel: "current_model"
      summarize: false
      summaryModel: "current_model"
      forcePrompt: false
      modelDisplayLabel: "TrueFoundry:OSS"
      iconURL: https://www.truefoundry.com/favicon.ico
```

## Using TrueFoundry with Custom Model Deployments
```yaml filename="librechat.yaml"
    - name: "TrueFoundry-Custom"
      apiKey: "${TRUEFOUNDRY_API_KEY}"
      baseURL: "${TRUEFOUNDRY_CUSTOM_ENDPOINT_URL}"
      headers:
        Authorization: "Bearer ${TRUEFOUNDRY_API_KEY}"
        x-tfy-workspace-id: "${TRUEFOUNDRY_WORKSPACE_ID}"
      models:
        default: ["custom-fine-tuned-model"]
        fetch: false
      titleConvo: true
      titleModel: "current_model"
      summarize: false
      summaryModel: "current_model"
      forcePrompt: false
      modelDisplayLabel: "TrueFoundry:Custom"
      iconURL: https://www.truefoundry.com/favicon.ico
``` 