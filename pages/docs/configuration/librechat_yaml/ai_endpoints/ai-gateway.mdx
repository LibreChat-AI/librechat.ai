---
title: Vercel AI Gateway
description: Example configuration for Vercel AI Gateway
---

# [Vercel AI Gateway](https://vercel.com/docs/ai-gateway)

> Vercel AI Gateway: [vercel.com/docs/ai-gateway](https://vercel.com/docs/ai-gateway)

**Notes:**

- **Known:** icon provided, fetching list of models is recommended. Use endpoint name `"Vercel"` in your configuration.

- Vercel AI Gateway provides a unified API for multiple AI providers including OpenAI, Anthropic, Google, and others through a single endpoint.

- `stop` is recommended to be dropped as different underlying models use different stop tokens.

- **Reasoning models:** AI Gateway supports extended thinking via the `reasoning` parameter with `enabled`, `effort` (none/minimal/low/medium/high/xhigh), and `max_tokens` options. Response includes `message.reasoning` with the thinking content.

```yaml
    - name: "Vercel"
      # For `apiKey` and `baseURL`, you can use environment variables that you define.
      # recommended environment variables:
      apiKey: "${AI_GATEWAY_API_KEY}"
      baseURL: "https://ai-gateway.vercel.sh/v1"
      titleConvo: true
      models:
        default:
          - "openai/gpt-5-mini"
          - "google/gemini-2.5-flash"
          - "deepseek/deepseek-v3.1"
          - "anthropic/claude-3-haiku"
        fetch: true
      titleModel: "openai/gpt-5-mini"
```

## Environment Variables

Add the following to your `.env` file:

```bash
AI_GATEWAY_API_KEY=your_api_key_here
```

## Supported Features

| Feature | Notes |
|---------|-------|
| Model fetching | Via `/v1/models` endpoint |
| Streaming | Full SSE support |
| Vision/Images | Depends on underlying model |
| Reasoning | Via `reasoning` parameter with `enabled` and `effort` |
| Tool calling | OpenAI-compatible function calling format |
