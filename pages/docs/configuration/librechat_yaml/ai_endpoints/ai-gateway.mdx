---
title: Vercel AI Gateway
description: Example configuration for Vercel AI Gateway
---

# [Vercel AI Gateway](https://vercel.com/docs/ai-gateway)

> Vercel AI Gateway: [vercel.com/docs/ai-gateway](https://vercel.com/docs/ai-gateway)

**Notes:**

- **Known:** icon provided, fetching list of models is recommended.

- Vercel AI Gateway provides a unified API for multiple AI providers including OpenAI, Anthropic, Google, and others through a single endpoint.

- `stop` is recommended to be dropped as different underlying models use different stop tokens.

- **Reasoning models:** AI Gateway supports extended thinking via the `reasoning` parameter with `enabled`, `effort` (none/minimal/low/medium/high/xhigh), and `max_tokens` options. Response includes `message.reasoning` with the thinking content.

```yaml
    - name: "ai-gateway"
      # For `apiKey` and `baseURL`, you can use environment variables that you define.
      # recommended environment variables:
      apiKey: "${AI_GATEWAY_API_KEY}"
      baseURL: "https://ai-gateway.vercel.sh/v1"
      models:
        default: ["gpt-5.2", "claude-sonnet-4-5"]
        fetch: true
      titleConvo: true
      titleModel: "gpt-5.2"
      # Recommended: Drop the stop parameter from the request as models use a variety of stop tokens.
      dropParams: ["stop"]
      modelDisplayLabel: "Vercel AI Gateway"
```

## Environment Variables

Add the following to your `.env` file:

```bash
AI_GATEWAY_API_KEY=your_api_key_here
```

## Supported Features

| Feature | Notes |
|---------|-------|
| Model fetching | Via `/v1/models` endpoint |
| Streaming | Full SSE support |
| Vision/Images | Depends on underlying model |
| Reasoning | Via `reasoning` parameter with `enabled` and `effort` |
| Tool calling | OpenAI-compatible function calling format |
