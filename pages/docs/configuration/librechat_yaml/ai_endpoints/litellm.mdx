---
title: LiteLLM
description: Example configuration for LiteLLM
---

# [LiteLLM](https://docs.litellm.ai/docs/)

**Notes:**

- Reference [Using LibreChat with LiteLLM Proxy](/blog/2023-11-30_litellm) for configuration.

```yaml filename="librechat.yaml"
- name: 'LiteLLM'
  apiKey: 'sk-from-config-file'
  baseURL: 'http://localhost:8000/v1'
  # if using LiteLLM example in docker-compose.override.yml.example, use "http://litellm:8000/v1"
  models:
    default: ['gpt-3.5-turbo']
    fetch: true
  titleConvo: true
  titleModel: 'gpt-3.5-turbo'
  summarize: false
  summaryModel: 'gpt-3.5-turbo'
  forcePrompt: false
  modelDisplayLabel: 'LiteLLM'
```

![image](https://github.com/danny-avila/LibreChat/assets/110412045/ddb4b2f3-608e-4034-9a27-3e94fc512034)
