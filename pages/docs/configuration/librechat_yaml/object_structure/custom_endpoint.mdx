# Custom Endpoint Object Structure
Each endpoint in the `custom` array should have the following structure:

## Example 

```yaml filename="Endpoint Object Structure"
endpoints:
    custom:
        # Example using Mistral AI API
    - name: "Mistral"
        apiKey: "${YOUR_ENV_VAR_KEY}"
        baseURL: "https://api.mistral.ai/v1"
        models: 
        default: ["mistral-tiny", "mistral-small", "mistral-medium", "mistral-large-latest"]
        titleConvo: true
        titleModel: "mistral-tiny" 
        modelDisplayLabel: "Mistral"
        # addParams:
        #   safe_prompt: true # Mistral specific value for moderating messages
        # NOTE: For Mistral, it is necessary to drop the following parameters or you will encounter a 422 Error:
        dropParams: ["stop", "user", "frequency_penalty", "presence_penalty"]
```

## name

**Key:**
<OptionTable
  options={[
    ['name', 'String', 'A unique name for the endpoint.', 'Will be used as the "title" in the Endpoints Selector'],
  ]}
/>

**Required**

**Example:**
```yaml filename="endpoints / custom / name"
name: "Mistral"
```

## apiKey

**Key:**
<OptionTable
  options={[
    ['apiKey', 'String (apiKey | "user_provided")', 'Your API key for the service. Can reference an environment variable, or allow user to provide the value.', 'It\'s highly recommended to use the env. variable reference for this field, i.e. `${YOUR_VARIABLE}`'],
  ]}
/>

**Required**

**Example:**
```yaml filename="endpoints / custom / apiKey"
apiKey: "${MISTRAL_API_KEY}"
```
or
```yaml filename="endpoints / custom / apiKey"
apiKey: "your_api_key"
```
or
```yaml filename="endpoints / custom / apiKey"
apiKey: "user_provided"
```

## baseURL

**Key:**
<OptionTable
  options={[
    ['baseURL', 'String (baseURL | "user_provided")', 'Base URL for the API. Can reference an environment variable, or allow user to provide the value.', 'It\'s highly recommended to use the env. variable reference for this field, i.e. `${YOUR_VARIABLE}`'],
  ]}
/>

**Required**

**Example:**
```yaml filename="endpoints / custom / baseURL"
baseURL: "https://api.mistral.ai/v1"
```
or
```yaml filename="endpoints / custom / baseURL"
baseURL: "${MISTRAL_BASE_URL}"
```
or
```yaml filename="endpoints / custom / baseURL"
baseURL: "user_provided"
```

**Notes:**

* If the `baseURL` you set is the full completions endpoint, you can set the [directEndpoint](#directendpoint) field to `true` to use it directly.
  - This is necessary because the app appends "/chat/completions" or "/completion" to the `baseURL` by default.

## iconURL

**Key:**
<OptionTable
  options={[
    ['iconURL', 'String', 'The URL to use as the Endpoint Icon.', ''],
  ]}
/>

**Default:** `""`

**Example:**
```yaml filename="endpoints / custom / iconURL"
iconURL: https://github.com/danny-avila/LibreChat/raw/main/docs/assets/LibreChat.svg
```
**Notes:**

* If you want to use existing project icons, define the endpoint `name` as one of the main endpoints (case-sensitive):
  - "openAI" | "azureOpenAI" | "google" | "anthropic" | "assistants" | "gptPlugins"
* There are also "known endpoints" (case-insensitive), which have icons provided. If your endpoint `name` matches the following names, you should omit this field:
  - "Mistral"
  - "Deepseek"
  - "OpenRouter"
  - "groq"
  - "APIpie"
  - "Anyscale"
  - "Fireworks"
  - "Perplexity"
  - "together.ai"
  - "ollama"
  - "xai"
  - "MLX"

## models

**Key:**
<OptionTable
  options={[
    ['models', 'Object', 'Configuration for models.', ''],
  ]}
/>

**Required**

**Properties:**

### default

**Key:**
<OptionTable
  options={[
    ['default', 'Array of Strings', 'An array of strings indicating the default models to use.', 'If fetching models fails, these defaults are used as a fallback.'],
  ]}
/>

**Required**

**Example:**
```yaml filename="endpoints / custom / models / default"
default:
  - "mistral-tiny"
  - "mistral-small"
  - "mistral-medium"
```

### fetch

**Key:**
<OptionTable
  options={[
    ['fetch', 'Boolean', 'When set to `true`, attempts to fetch a list of models from the API.', 'May cause slowdowns during initial use of the app if the response is delayed. Defaults to `false`.'],
  ]}
/>

**Default:** `false`

**Example:**
```yaml filename="endpoints / custom / models / fetch"
fetch: true
```

### userIdQuery

**Key:**
<OptionTable
  options={[
    ['userIdQuery', 'Boolean', 'When set to `true`, adds the LibreChat user ID as a query parameter to the API models request.', ''],
  ]}
/>

**Default:** `false`

**Example:**
```yaml filename="endpoints / custom / models / userIdQuery"
userIdQuery: true
```

## titleConvo

**Key:**
<OptionTable
  options={[
    ['titleConvo', 'Boolean', 'Enables title conversation when set to `true`.', ''],
  ]}
/>

**Default:** `false`

**Example:**
```yaml filename="endpoints / custom / titleConvo"
titleConvo: true
```

## titleMethod

**Key:**
<OptionTable
  options={[
    ['titleMethod', 'String ("completion" | "functions")', 'Chooses between "completion" or "functions" for title method.', 'Defaults to "completion" if omitted.'],
  ]}
/>

**Default:** `"completion"`

**Example:**
```yaml filename="endpoints / custom / titleMethod"
titleMethod: "completion"
```

## titleModel

**Key:**
<OptionTable
  options={[
    ['titleModel', 'String', 'Specifies the model to use for titles.', 'Defaults to "gpt-3.5-turbo" if omitted. May cause issues if "gpt-3.5-turbo" is not available. You can also dynamically use the current conversation model by setting it to "current_model".'],
  ]}
/>

**Default:** `"gpt-3.5-turbo"`

**Example:**
```yaml filename="endpoints / custom / titleModel"
titleModel: "mistral-tiny"
```
or
```yaml filename="endpoints / custom / titleModel"
titleModel: "current_model"
```

## summarize

**Key:**
<OptionTable
  options={[
    ['summarize', 'Boolean', 'Enables summarization when set to `true`.', 'This feature requires an OpenAI Functions compatible API'],
  ]}
/>

**Default:** `false`

**Example:**
```yaml filename="endpoints / custom / summarize"
summarize: false
```

## summaryModel

**Key:**
<OptionTable
  options={[
    ['summaryModel', 'String', 'Specifies the model to use if summarization is enabled.', 'Defaults to "gpt-3.5-turbo" if omitted. May cause issues if "gpt-3.5-turbo" is not available.'],
  ]}
/>

**Default:** `"gpt-3.5-turbo"`

**Example:**
```yaml filename="endpoints / custom / summaryModel"
summaryModel: "mistral-tiny"
```

## forcePrompt

**Key:**
<OptionTable
  options={[
    ['forcePrompt', 'Boolean', 'If `true`, sends a `prompt` parameter instead of `messages`.', 'Combines all messages into a single text payload or "prompt", following OpenAI format, which uses the `/completions` endpoint of your baseURL rather than `/chat/completions`.'],
  ]}
/>

**Default:** `false`

**Example:**
```yaml filename="endpoints / custom / forcePrompt"
forcePrompt: false
```

## modelDisplayLabel

**Key:**
<OptionTable
  options={[
    ['modelDisplayLabel', 'String', 'The label displayed in messages next to the Icon for the current AI model.', 'The display order is: 1. Custom name set via preset (if available), 2. Label derived from the model name (if applicable), 3. This value is used if the above are not specified. Defaults to "AI".'],
  ]}
/>

**Default:** `"AI"`

**Example:**
```yaml filename="endpoints / custom / modelDisplayLabel"
modelDisplayLabel: "Mistral"
```

## addParams

**Key:**
<OptionTable
  options={[
    ['addParams', 'Object/Dictionary', 'Adds additional parameters to requests.', 'Adds/Overrides parameters. Useful for specifying API-specific options.'],
  ]}
/>

**Example:**
```yaml filename="endpoints / custom / addParams"
addParams:
  safe_prompt: true
  max_tokens: 2048
```
**Notes:**
- The `addParams` field allows you to include additional parameters that are not part of the default payload(see the ["Default Parameters"](/docs/configuration/librechat_yaml/object_structure/default_params) section). This is particularly useful for API-specific options.
- For example, if an API requires the `max_tokens` parameter, you can add it here. By default, LibreChat [does not send](/docs/configuration/librechat_yaml/object_structure/default_params) `max_tokens` to use the maximum amount of tokens available, which is the default behavior of the OpenAI API. However, some alternate APIs require this field, or it may default to a very low value, causing your responses to appear cut off. In such cases, you should specify the desired value for `max_tokens` in the `addParams` field.
## dropParams

**Key:**
<OptionTable
  options={[
    ['dropParams', 'Array/List of Strings', 'Removes default parameters from requests.', 'Excludes specified default parameters. Useful for APIs that do not accept or recognize certain parameters.'],
  ]}
/>

**Example:**
```yaml filename="endpoints / custom / dropParams"
dropParams:
  - "stop"
  - "user"
  - "frequency_penalty"
  - "presence_penalty"
```
**Note:** 
- The `dropParams` field allows you to remove ["Default Parameters"](/docs/configuration/librechat_yaml/object_structure/default_params) that are sent with every request. This is helpful when working with APIs that do not accept or recognize certain parameters.

## headers

**Key:**
<OptionTable
  options={[
    ['headers', 'Object/Dictionary', 'Adds additional headers to requests. Can reference an environment variable', 'The `headers` object specifies custom headers for requests. Useful for authentication and setting content types.'],
  ]}
/>

**Example:**
```yaml filename="endpoints / custom / headers"
headers:
  x-api-key: "${ENVIRONMENT_VARIABLE}"
  Content-Type: "application/json"
```
**Note:** Supports dynamic environment variable values, which use the format: `"${VARIABLE_NAME}"`.

## directEndpoint

**Key:**
<OptionTable
  options={[
    ['directEndpoint', 'Boolean', 'When set to `true`, treats the configured `baseURL` as the completions endpoint to be used', ''],
  ]}
/>

**Default:** `false`

**Example:**
```yaml filename="endpoints / custom / directEndpoint"
directEndpoint: true
```

## titleMessageRole

**Key:**
<OptionTable
  options={[
    ['titleMessageRole', 'String', 'Specifies the role value to use in the message payload for title generation.', 'Defaults to "system" if omitted. May cause issues if "system" is not a valid value, which is sometimes the case for single message payloads, as it is for title generation.'],
  ]}
/>

**Default:** `"system"`

**Example:**
```yaml filename="endpoints / custom / titleMessageRole"
titleMessageRole: "user"
```