# Shared Endpoint Settings

This page describes the shared configuration settings for all endpoints. The settings highlighted here are available to all configurations under the ["Endpoints"](/docs/configuration/librechat_yaml/object_structure/config#endpoints) field unless noted otherwise.

## Example Configuration

```yaml filename="Shared Endpoint Settings"
endpoints:
  openAI:
    streamRate: 25
    titleModel: "gpt-4o-mini"
  anthropic:
    streamRate: 25
    titleModel: "claude-3-5-haiku-20241022"
  bedrock:
    streamRate: 25
    titleModel: "us.amazon.nova-lite-v1:0"
  google:
    streamRate: 1
    titleModel: "gemini-2.0-flash-lite"
  azureOpenAI:
    streamRate: 20
    titleModel: "gpt-4o-mini"
  assistants:
    streamRate: 30
  azureAssistants:
    streamRate: 30
  # the `all` setting would override all the above values, making them unnecessary to be set
  all:
    streamRate: 20
```

## streamRate

**Key:**
<OptionTable
  options={[
    ['streamRate', 'Number', 'The rate at which data is streamed from the endpoint. Useful for controlling the pace of streaming data.', 'streamRate: 25'],
  ]}
/>

**Default:** 1

> Allows for streaming data at the fastest rate possible while allowing the system to wait for the next tick

## titleModel

**Key:**
<OptionTable
  options={[
    ['titleModel', 'String', 'Specifies the model to use for titles.', 'Defaults to system default for the current endpoint if omitted. May cause issues if the system default model is not available. You can also dynamically use the current conversation model by setting it to "current_model".'],
  ]}
/>

**Default:** System default for the current endpoint
**Notes:** It isn't yet possible to set a `titleModel` for the `all` key. This setting must be set individually for each endpoint.

---

**Notes:**
- The `all` setting would override all individual endpoint values, making those specific settings unnecessary if used.
- The value can be customized for each endpoint or set globally using the `all` key.
- Recommended values are between 25-40 for a smooth streaming experience
- Using a higher rate is a must when serving the app to many users at scale.

---

# Endpoint Settings
- [Custom Endpoints](/docs/configuration/librechat_yaml/object_structure/custom_endpoint)
- [OpenAI](/docs/configuration/pre_configured_ai/openai)
- [Anthropic](/docs/configuration/pre_configured_ai/anthropic)
- [Bedrock](/docs/configuration/pre_configured_ai/bedrock)
- [Google](/docs/configuration/pre_configured_ai/google)
- [Azure OpenAI](/docs/configuration/librechat_yaml/object_structure/azure_openai)
- [Assistants](/docs/configuration/librechat_yaml/object_structure/assistants_endpoint)